/*
This is a simple implementation of a neural network using gradient descent.
The main purpose is to explain the concept of gradient descent and how it is 
used to train a neural network for people who are coming from systems background
Pull request are welcome to increase simplicity and readability of the code.
*/
#include <stdio.h>
#include <math.h>
#include <stdlib.h>
#include <time.h>

// We will implement a simple neural network with 2 inputs and 1 output. 
// The network will train on samples being generated randomly by an linear equation and would guess the weights of the equation. 
// The equation is y = 2*x1 + 5*x2

// Weights of the neural network
float w1 = 0;
float w2 = 0;

// Gradients of the neural network
float g1 = 0;
float g2 = 0;

// This is the target function we want to approximate using a neural network
// We call it black_box because we assume that we don't know the actual implementation of the function. 
// We train our neural network on samples generated by this function, to emulate the function.

// You could play with changing the weights of the function to see how the model performs
float black_box(float x1, float x2) {
    
    return (2*x1 + 5*x2 );
}



// Initialize the weights to random values
void init_weights() {
    w1 =  rand() % 100 / 100.0;
    w2 =  rand() % 100 / 100.0;
}

// Adjust the weights based on the gradient and learning rate
void adjust_weights(float learning_rate) {
    w1 += g1*learning_rate;
    w2 += g2*learning_rate;
}

// Forward Propogation: Run the model with current weight and calculate the output of the model
float model(int x1, int x2) {
    return w1*x1 + w2*x2 ;
}


// Calculate the gradient of the error with respect to the weights
void calculate_gradient(float x1, float x2, float error) {
    // Gradient is the derivative of the error with respect to each weight
    // E = (target - y)
    // g1 calculation: how much the error changes with respect to w1
    // g2 calculation: how much the error changes with respect to w2

    // dE/dw1 =  dE/dy * dy/dw1
    // Where dE/dy is how much error changes with respect to the output 
    // and dy/dw1 is the derivative of the model with respect to w1 which is x1
    // dE/dw1 =  2*E * x1
    g1 = 2*error * x1;
    g2 = 2*error * x2;
}

int main() {

    // Initialize the seed for random number generation
    srand(time(NULL));

    // Initialize the weights
    init_weights();

    // Learning rate
    // Play with this value to see how the model converges
    float learning_rate = 0.0001;  // Smaller learning rate due to squared error
    float total_error = 0;
    float x1, x2;
    float target, output, error;

    for (int epoch = 0; epoch < 1000; epoch++) {
        
        // Let's generate a random input for our model
        x1 = rand() % 100;
        x2 = rand() % 100;

        // Let's generate the target value (y) for training our model
        target = black_box(x1, x2);

        // So our labeled input data is now (x1, x2, target)

        // Let's run the model with current weights and calculate what model predicts
        output = model(x1, x2);

        // for initial run, the output would be far from target.
        // Calculate the error
        error = target - output;
 

        // Calculate new gradients for this sample
        // We need to calculate the gradient every time we change the weights. 
        // This is because the gradient is a function of the weights and the input data.
        calculate_gradient(x1, x2, error);

        // Adjust the weights based on the gradient and learning rate
        adjust_weights(learning_rate);
        
        // Print average error every 100 epochs
        if (epoch % 100 == 0) {
            printf("Epoch %d, Average MSE: %f\n", epoch, error);
        }
        
        // Early stopping condition
        if ( error * error  < 0.0001) {
            printf("Converged at epoch %d\n", epoch);
            break;
        }
    }

    printf("\n Final weights - w1: %f, w2: %f\n", w1, w2);
    // Test the model
    printf("\nTesting the model:\n");
    for (int i = 0; i < 10; i++) {
        x1 = rand() % 100;
        x2 = rand() % 100;
        float target = black_box(x1, x2);
        float output = model(x1, x2);
        printf("Input: (%f, %f), Target: %f, Prediction: %f\n", 
               x1, x2, target, output);
    }
    
    return 0;
}